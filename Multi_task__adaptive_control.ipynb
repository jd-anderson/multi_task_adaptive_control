{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15386e-de71-40de-9f9e-c5b86b31c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# Paper Figures: CE + (R)CSI with Unicycles, Baselines, Bands\n",
    "# Figures:\n",
    "# 1) Homogeneous\n",
    "# 2) Heterogeneous (eps_var > 0)\n",
    "# 3) Heterogeneous + Byzantine (robust aggregation)\n",
    "# 4) Misclassification (Homogeneous)\n",
    "# 5) Aggregation comparison (trimmed vs geometric median)\n",
    "# =========================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "from itertools import permutations\n",
    "\n",
    "# ------------------ formatting defaults ------------------\n",
    "BIG = 16\n",
    "MID = 14\n",
    "SML = 12\n",
    "\n",
    "def stylize_axes(ax, title=None, ylabel=None, xlabel=None, bold_title=True, bold_ylabel=True):\n",
    "    if title is not None:\n",
    "        ax.set_title(title, fontsize=BIG, fontweight=('bold' if bold_title else 'normal'))\n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel, fontsize=MID, fontweight=('bold' if bold_ylabel else 'normal'))\n",
    "    if xlabel is not None:\n",
    "        ax.set_xlabel(xlabel, fontsize=MID)\n",
    "    ax.grid(True, alpha=0.35)\n",
    "    ax.tick_params(labelsize=SML)\n",
    "\n",
    "# ------------------ utilities ------------------\n",
    "\n",
    "def align_labels_best_perm(pred_labels: np.ndarray,\n",
    "                           true_labels: np.ndarray,\n",
    "                           K: int):\n",
    "    C = np.zeros((K, K), dtype=int)\n",
    "    for j in range(K):\n",
    "        for k in range(K):\n",
    "            C[j, k] = np.sum((pred_labels == j) & (true_labels == k))\n",
    "    best_p, best_score = None, -1\n",
    "    for p in permutations(range(K)):\n",
    "        score = sum(C[j, p[j]] for j in range(K))\n",
    "        if score > best_score:\n",
    "            best_score, best_p = score, np.array(p, dtype=int)\n",
    "    remapped = best_p[pred_labels]\n",
    "    mis = int(np.sum(remapped != true_labels))\n",
    "    return remapped, mis, best_p\n",
    "\n",
    "def spectral_radius(A):\n",
    "    return float(np.max(np.abs(np.linalg.eigvals(A))))\n",
    "\n",
    "# ------------------ prototypes & systems (Unicycle) ------------------\n",
    "\n",
    "def get_prototypes_from_paper():\n",
    "    \"\"\"\n",
    "    Three different unicycle models (discrete-time Euler linearization).\n",
    "    States: [x, y, θ], Inputs: [v, ω].\n",
    "    \"\"\"\n",
    "    def unicycle_AB(v0, theta0, dt=0.1):\n",
    "        A = np.array([\n",
    "            [0, 0, -v0 * np.sin(theta0)],\n",
    "            [0, 0,  v0 * np.cos(theta0)],\n",
    "            [0, 0, 0]\n",
    "        ], dtype=float)\n",
    "        B = np.array([\n",
    "            [np.cos(theta0), 0],\n",
    "            [np.sin(theta0), 0],\n",
    "            [0, 1]\n",
    "        ], dtype=float)\n",
    "        A_d = np.eye(3) + dt * A\n",
    "        B_d = dt * B\n",
    "        return A_d, B_d\n",
    "\n",
    "    configs = [\n",
    "        (1.0, np.deg2rad(0.0),  0.1),  # heading 0°, speed 1.0\n",
    "        (1.0, np.deg2rad(45.0), 0.1),  # heading 45°, speed 1.0\n",
    "        (0.8, np.deg2rad(90.0), 0.1),  # heading 90°, speed 0.8\n",
    "    ]\n",
    "    A_list, B_list = [], []\n",
    "    for v0, th0, dt in configs:\n",
    "        A, B = unicycle_AB(v0, th0, dt)\n",
    "        A_list.append(A); B_list.append(B)\n",
    "    return A_list, B_list\n",
    "\n",
    "def make_per_system_AB(Aj, Bj, cluster_sizes, hetero_eps=0.0, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    A_list, B_list, ids = [], [], []\n",
    "    for j, sz in enumerate(cluster_sizes):\n",
    "        for _ in range(sz):\n",
    "            if hetero_eps > 0:\n",
    "                A_i = Aj[j] + hetero_eps * rng.standard_normal(Aj[j].shape)\n",
    "                B_i = Bj[j] + hetero_eps * rng.standard_normal(Bj[j].shape)\n",
    "            else:\n",
    "                A_i, B_i = Aj[j], Bj[j]\n",
    "            A_list.append(A_i); B_list.append(B_i); ids.append(j)\n",
    "    return A_list, B_list, np.array(ids, dtype=int)\n",
    "\n",
    "# ------------------ LQR ------------------\n",
    "\n",
    "def dare_iterative(A, B, Q, R, max_iter=5000, tol=1e-10, eps=1e-9):\n",
    "    P = Q.copy(); AT, BT = A.T, B.T\n",
    "    for _ in range(max_iter):\n",
    "        RB = R + BT @ P @ B; RB = 0.5*(RB+RB.T)\n",
    "        w = np.linalg.eigvalsh(RB)\n",
    "        if w.min() <= eps: RB += (eps - w.min() + 1e-12)*np.eye(RB.shape[0])\n",
    "        K = np.linalg.solve(RB, BT @ P @ A)\n",
    "        Pn = AT @ P @ A - AT @ P @ B @ K + Q; Pn = 0.5*(Pn+Pn.T)\n",
    "        if not np.all(np.isfinite(Pn)): break\n",
    "        if np.linalg.norm(Pn-P,'fro') <= tol*(1+np.linalg.norm(P,'fro')):\n",
    "            P = Pn; break\n",
    "        P = Pn\n",
    "    return P\n",
    "\n",
    "def lqr_gain(A,B,Q=None,R=None):\n",
    "    n,m = A.shape[0], B.shape[1]\n",
    "    if Q is None: Q = np.eye(n)\n",
    "    if R is None: R = np.eye(m)\n",
    "    P = dare_iterative(A,B,Q,R)\n",
    "    RB = R + B.T@P@B; RB = 0.5*(RB+RB.T)\n",
    "    w = np.linalg.eigvalsh(RB)\n",
    "    if w.min() <= 1e-9: RB += (1e-9 - w.min() + 1e-12)*np.eye(m)\n",
    "    K = np.linalg.solve(RB, B.T@P@A)\n",
    "    return -K, P\n",
    "\n",
    "# ------------------ CSI stats rollouts ------------------\n",
    "\n",
    "def rollout_collect(A,B,K,T_steps,sigma_u,sigma_w,Q,R,rng,K_fallback=None):\n",
    "    n,m = A.shape[0], B.shape[1]\n",
    "    x = np.zeros((n,1))\n",
    "    useK = K\n",
    "    if K_fallback is not None and spectral_radius(A+B@K) >= 0.999:\n",
    "        useK = K_fallback\n",
    "    XZ = np.zeros((n,n+m)); ZZ = np.zeros((n+m,n+m)); Xnorm2=0.0\n",
    "    for _ in range(T_steps):\n",
    "        g = rng.standard_normal((m,1)); w = sigma_w*rng.standard_normal((n,1))\n",
    "        u = useK @ x + sigma_u*g\n",
    "        x_next = A @ x + B @ u + w\n",
    "        z = np.vstack([x,u])\n",
    "        XZ += x_next @ z.T; ZZ += z @ z.T\n",
    "        Xnorm2 += float((x_next.T @ x_next)[0,0])\n",
    "        x = x_next\n",
    "    return XZ, ZZ, Xnorm2\n",
    "\n",
    "# ------------------ analytic steady-state regret ------------------\n",
    "\n",
    "def solve_discrete_lyapunov_iter(F, W, tol=1e-10, max_iter=10000):\n",
    "    X = np.zeros_like(W)\n",
    "    for _ in range(max_iter):\n",
    "        Xn = F @ X @ F.T + W\n",
    "        if np.linalg.norm(Xn - X, 'fro') <= tol * (1 + np.linalg.norm(X, 'fro')):\n",
    "            return 0.5*(Xn + Xn.T)\n",
    "        X = Xn\n",
    "    return 0.5*(X + X.T)\n",
    "\n",
    "def steady_state_per_step_cost(A, B, K, Q, R, sigma_u, sigma_w):\n",
    "    n, m = A.shape[0], B.shape[1]\n",
    "    F = A + B @ K\n",
    "    if spectral_radius(F) >= 1.0:\n",
    "        return np.inf\n",
    "    W = (sigma_w**2) * np.eye(n) + (sigma_u**2) * (B @ B.T)\n",
    "    X = solve_discrete_lyapunov_iter(F, W)\n",
    "    Jx = np.trace(Q @ X)\n",
    "    Ju = np.trace(R @ (K @ X @ K.T + (sigma_u**2) * np.eye(m)))\n",
    "    return float(Jx + Ju)\n",
    "\n",
    "def perstep_cost_safe(A,B,K,Q,R,su,sw,K_fallback=None):\n",
    "    F = A + B @ K\n",
    "    if spectral_radius(F) >= 0.999 and K_fallback is not None:\n",
    "        return steady_state_per_step_cost(A,B,K_fallback,Q,R,su,sw)\n",
    "    return steady_state_per_step_cost(A,B,K,Q,R,su,sw)\n",
    "\n",
    "# ------------------ Byzantine mask & corruption (adaptive) ------------------\n",
    "\n",
    "def sample_byzantine_mask(cluster_sizes, rho_byz=0.2, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    M = sum(cluster_sizes)\n",
    "    is_byz = np.zeros(M, dtype=bool)\n",
    "    n_b = int(np.floor(rho_byz * M))\n",
    "    if n_b > 0:\n",
    "        idx = rng.choice(M, size=n_b, replace=False)\n",
    "        is_byz[idx] = True\n",
    "    return is_byz\n",
    "\n",
    "def corrupt_stats_adaptive(\n",
    "    XZ, ZZ, Xn, Theta_pub, true_cluster=None, rng=None,\n",
    "    mode=\"blend_to_wrong_cluster\", strength=0.6\n",
    "):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    Kc = len(Theta_pub)\n",
    "    n, nm = XZ.shape\n",
    "    beta = max(0.0, min(1.0, float(strength)))\n",
    "\n",
    "    def residual_under(T):\n",
    "        t1 = np.sum(T * XZ)\n",
    "        t2 = np.trace(T @ ZZ @ T.T)\n",
    "        return -2.0 * t1 + t2\n",
    "\n",
    "    cand = list(range(Kc))\n",
    "    if true_cluster is not None and true_cluster in cand:\n",
    "        cand.remove(true_cluster)\n",
    "    if len(cand) == 0:\n",
    "        cand = list(range(Kc))\n",
    "\n",
    "    res_vals = [residual_under(Theta_pub[j]) for j in cand]\n",
    "    j_tgt = cand[int(np.argmin(res_vals))]\n",
    "    T_tgt = Theta_pub[j_tgt]\n",
    "\n",
    "    if mode == \"residual_descent\":\n",
    "        grad = XZ - T_tgt @ ZZ\n",
    "        XZc = XZ - beta * grad\n",
    "    else:\n",
    "        XZ_tgt = T_tgt @ ZZ\n",
    "        XZc = (1.0 - beta) * XZ + beta * XZ_tgt\n",
    "\n",
    "    eps = 1e-6\n",
    "    XZc = XZc + eps * rng.standard_normal(XZ.shape)\n",
    "    return XZc, ZZ, Xn\n",
    "\n",
    "# ------------------ Robust CSI (RCSI): hard-EM with robust aggregation ------------------\n",
    "\n",
    "def geometric_median_matrix(thetas, tol=1e-6, max_iter=200):\n",
    "    X = np.mean(np.stack(thetas, axis=0), axis=0)\n",
    "    for _ in range(max_iter):\n",
    "        diffs = [T - X for T in thetas]\n",
    "        dists = np.array([np.linalg.norm(D, 'fro') + 1e-12 for D in diffs])\n",
    "        w = 1.0 / dists\n",
    "        X_new = sum(wi*Ti for wi,Ti in zip(w, thetas)) / w.sum()\n",
    "        if np.linalg.norm(X_new - X, 'fro') <= tol * (1 + np.linalg.norm(X, 'fro')):\n",
    "            return X_new\n",
    "        X = X_new\n",
    "    return X\n",
    "\n",
    "def rcsi_update_hard_em(\n",
    "    XZ_list, ZZ_list, Xnorm2, Theta_init, Kc,\n",
    "    steps=3, lam=1e-6, seed=None,\n",
    "    alpha_trim=0.0, use_geom_median=False\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    M = len(XZ_list); Theta = [T.copy() for T in Theta_init]\n",
    "    nm = ZZ_list[0].shape[0]\n",
    "\n",
    "    for _ in range(steps):\n",
    "        # E-step\n",
    "        scores = np.zeros((M, Kc))\n",
    "        for j in range(Kc):\n",
    "            Tj = Theta[j]\n",
    "            t1 = np.array([np.sum(Tj * XZ_list[i]) for i in range(M)])\n",
    "            t2 = np.array([np.trace(Tj @ ZZ_list[i] @ Tj.T) for i in range(M)])\n",
    "            scores[:, j] = Xnorm2 - 2.0 * t1 + t2\n",
    "        labels = scores.argmin(axis=1)\n",
    "\n",
    "        # Reseed empties\n",
    "        for j in range(Kc):\n",
    "            if np.sum(labels == j) == 0:\n",
    "                worst_i = int(np.argmax(scores[np.arange(M), labels]))\n",
    "                ZZr = ZZ_list[worst_i] + lam * np.eye(nm)\n",
    "                Theta[j] = XZ_list[worst_i] @ np.linalg.pinv(ZZr)\n",
    "                labels[worst_i] = j\n",
    "\n",
    "        # M-step (robust)\n",
    "        newTheta = []\n",
    "        for j in range(Kc):\n",
    "            idx = np.where(labels == j)[0]\n",
    "            if len(idx) == 0:\n",
    "                newTheta.append(Theta[j]); continue\n",
    "\n",
    "            # residual ranking\n",
    "            res = [(i, scores[i, j]) for i in idx]\n",
    "            res.sort(key=lambda p: p[1])\n",
    "            keep = max(1, int(np.ceil((1.0 - alpha_trim) * len(idx))))\n",
    "            kept_idx = [i for i,_ in res[:keep]]\n",
    "\n",
    "            if not use_geom_median:\n",
    "                XZ_sum = sum(XZ_list[i] for i in kept_idx)\n",
    "                ZZ_sum = sum(ZZ_list[i] for i in kept_idx) + lam * np.eye(nm)\n",
    "                Tj_new = XZ_sum @ np.linalg.pinv(ZZ_sum)\n",
    "            else:\n",
    "                thetas = []\n",
    "                for i in kept_idx:\n",
    "                    ZZr = ZZ_list[i] + lam * np.eye(nm)\n",
    "                    thetas.append(XZ_list[i] @ np.linalg.pinv(ZZr))\n",
    "                Tj_new = geometric_median_matrix(thetas)\n",
    "\n",
    "            newTheta.append(Tj_new)\n",
    "        Theta = newTheta\n",
    "\n",
    "    return Theta, labels\n",
    "\n",
    "# ------------------ Seeding ------------------\n",
    "\n",
    "def seed_theta_from_ols_kpp(XZ_list, ZZ_list, Kc, lam=1e-6, seed=None):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    M = len(XZ_list); n, nm = XZ_list[0].shape\n",
    "    Theta_i = np.empty((M, n, nm))\n",
    "    for i in range(M):\n",
    "        ZZr = ZZ_list[i] + lam * np.eye(ZZ_list[i].shape[0])\n",
    "        Theta_i[i] = XZ_list[i] @ np.linalg.pinv(ZZr)\n",
    "    flat = Theta_i.reshape(M, -1)\n",
    "    centers = [Theta_i[rng.integers(M)]]\n",
    "    d2 = np.full(M, np.inf)\n",
    "    for _ in range(1, Kc):\n",
    "        last = centers[-1].reshape(1, -1)\n",
    "        d2 = np.minimum(d2, np.sum((flat - last)**2, axis=1))\n",
    "        probs = d2 / d2.sum()\n",
    "        centers.append(Theta_i[rng.choice(M, p=probs)])\n",
    "    return [c.copy() for c in centers]\n",
    "\n",
    "# ------------------ Main CE + (R)CSI loop ------------------\n",
    "\n",
    "def regret_with_clustering(\n",
    "    A_list, B_list, Nc, cluster_sizes,\n",
    "    epochs=6, tau1=100, sigma_u_seq=(0.6,0.45,0.35,0.25,0.18,0.12,0.08),\n",
    "    sigma_w=0.10, csi_steps=3, seed=0,\n",
    "    oracle_same_noise=True, common_K0=True,\n",
    "    init_mode=\"cold\", init_noise=0.8, lam_ridge=1e-6,\n",
    "    # Byzantine + Robust params\n",
    "    rho_byz=0.0, byz_strength=0.6, byz_mode=\"adaptive\",\n",
    "    alpha_trim=0.0, use_geom_median=False\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    M = len(A_list); n,m = A_list[0].shape[0], B_list[0].shape[1]\n",
    "    Q = np.eye(n); R = np.eye(m)\n",
    "    true_ids = np.concatenate([np.full(sz,j) for j,sz in enumerate(cluster_sizes)])\n",
    "\n",
    "    K_star = [lqr_gain(A_list[i],B_list[i],Q,R)[0] for i in range(M)]\n",
    "\n",
    "    if common_K0:\n",
    "        K0,_ = lqr_gain(A_list[0],B_list[0],Q,R)\n",
    "        K_hat = [K0.copy() for _ in range(M)]\n",
    "    else:\n",
    "        K_hat = [0.8*K_star[i] for i in range(M)]\n",
    "\n",
    "    # public models for adversary\n",
    "    Theta_pub = [np.zeros((n, n+m)) for _ in range(Nc)]\n",
    "\n",
    "    # epoch schedule\n",
    "    taus=[tau1]\n",
    "    for _ in range(1,epochs):\n",
    "        taus.append(2*taus[-1])\n",
    "\n",
    "    is_byz = sample_byzantine_mask(cluster_sizes, rho_byz=rho_byz, seed=seed)\n",
    "\n",
    "    cum_reg=[]; T_axis=[]; mis_epoch=[]\n",
    "    t_now=0\n",
    "\n",
    "    for k in range(epochs):\n",
    "        T_k = taus[k]\n",
    "        sig_u = sigma_u_seq[k] if k < len(sigma_u_seq) else sigma_u_seq[-1]\n",
    "        sig_u_or = sig_u if oracle_same_noise else 0.0\n",
    "\n",
    "        # Collect clean stats\n",
    "        XZ_clean=[]; ZZ_clean=[]; Xn_clean=[]\n",
    "        for i in range(M):\n",
    "            XZ_i,ZZ_i,Xn_i = rollout_collect(A_list[i],B_list[i],K_hat[i],\n",
    "                                             T_k,sig_u,sigma_w,Q,R,rng,K_fallback=K_star[i])\n",
    "            XZ_clean.append(XZ_i); ZZ_clean.append(ZZ_i); Xn_clean.append(Xn_i)\n",
    "\n",
    "        # One-time warm start\n",
    "        if k==0 and init_mode==\"cold\":\n",
    "            Theta_seed = seed_theta_from_ols_kpp(XZ_clean, ZZ_clean, Nc, lam=lam_ridge, seed=seed)\n",
    "            Theta_pub = [T.copy() for T in Theta_seed]\n",
    "\n",
    "        # Apply adversarial corruption (if any)\n",
    "        XZ_list=[]; ZZ_list=[]; Xn_list=[]\n",
    "        for i in range(M):\n",
    "            if is_byz[i] and byz_strength > 0 and rho_byz > 0:\n",
    "                XZ_i, ZZ_i, Xn_i = corrupt_stats_adaptive(\n",
    "                    XZ_clean[i], ZZ_clean[i], Xn_clean[i],\n",
    "                    Theta_pub, true_cluster=true_ids[i], rng=rng,\n",
    "                    mode=\"blend_to_wrong_cluster\" if byz_mode==\"adaptive\" else \"residual_descent\",\n",
    "                    strength=byz_strength\n",
    "                )\n",
    "            else:\n",
    "                XZ_i, ZZ_i, Xn_i = XZ_clean[i], ZZ_clean[i], Xn_clean[i]\n",
    "            XZ_list.append(XZ_i); ZZ_list.append(ZZ_i); Xn_list.append(Xn_i)\n",
    "\n",
    "        # Per-epoch regret\n",
    "        perstep_actual = 0.0; perstep_oracle = 0.0\n",
    "        for i in range(M):\n",
    "            perstep_actual += perstep_cost_safe(A_list[i], B_list[i], K_hat[i], Q, R, sig_u, sigma_w, K_fallback=K_star[i])\n",
    "            perstep_oracle += steady_state_per_step_cost(A_list[i], B_list[i], K_star[i], Q, R, sig_u, sigma_w)\n",
    "        delta_epoch = (perstep_actual - perstep_oracle) * T_k\n",
    "\n",
    "        # Update (CSI or RCSI depending on params)\n",
    "        if rho_byz == 0 and alpha_trim == 0 and not use_geom_median:\n",
    "            # Clean CSI (fast path)\n",
    "            Theta_new, raw_labels = rcsi_update_hard_em(\n",
    "                XZ_clean, ZZ_clean, np.array(Xn_clean), Theta_pub,\n",
    "                Nc, steps=csi_steps, lam=lam_ridge, seed=seed+k,\n",
    "                alpha_trim=0.0, use_geom_median=False\n",
    "            )\n",
    "        else:\n",
    "            # Robust RCSI\n",
    "            Theta_new, raw_labels = rcsi_update_hard_em(\n",
    "                XZ_list, ZZ_list, np.array(Xn_list), Theta_pub,\n",
    "                Nc, steps=csi_steps, lam=lam_ridge, seed=seed+k,\n",
    "                alpha_trim=alpha_trim, use_geom_median=use_geom_median\n",
    "            )\n",
    "\n",
    "        # Align, reorder\n",
    "        mapped_labels, mis, perm = align_labels_best_perm(raw_labels, true_ids, Nc)\n",
    "        perm = np.asarray(perm); perm_inv = np.argsort(perm)\n",
    "        Theta_ordered = [Theta_new[perm_inv[j]] for j in range(Nc)]\n",
    "        mis_epoch.append(mis)\n",
    "\n",
    "        # Publish, update controllers\n",
    "        Theta_pub = [T.copy() for T in Theta_ordered]\n",
    "        for i in range(M):\n",
    "            j = mapped_labels[i]\n",
    "            Ahat = Theta_ordered[j][:,:n]; Bhat = Theta_ordered[j][:,n:]\n",
    "            K_hat[i] = lqr_gain(Ahat,Bhat,Q,R)[0]\n",
    "\n",
    "        t_now += T_k; T_axis.append(t_now)\n",
    "        cum_reg.append((cum_reg[-1] if cum_reg else 0.0) + delta_epoch)\n",
    "\n",
    "    return np.array(T_axis), np.array(cum_reg)/M, {'mis_epoch':np.array(mis_epoch)}\n",
    "\n",
    "# ------------------ Baseline: single-system CE (no clustering) ------------------\n",
    "\n",
    "def ensure_stable_gain(A, B, K, rho_target=0.995, max_iter=40):\n",
    "    \"\"\"Project K -> alpha*K so that rho(A + B K) <= rho_target (<1).\"\"\"\n",
    "    if spectral_radius(A + B @ K) <= rho_target:\n",
    "        return K, 1.0\n",
    "    lo, hi = 0.0, 1.0\n",
    "    K0 = K.copy()\n",
    "    for _ in range(max_iter):\n",
    "        mid = 0.5 * (lo + hi)\n",
    "        if spectral_radius(A + B @ (mid * K0)) <= rho_target:\n",
    "            lo = mid\n",
    "        else:\n",
    "            hi = mid\n",
    "    return lo * K0, lo\n",
    "\n",
    "def simulate_epoch_cost_with_noise(A, B, K, Q, R, T, su, sw, g_seq, w_seq):\n",
    "    \"\"\"\n",
    "    Compute cumulative quadratic cost over one epoch with fixed noise sequences.\n",
    "    g_seq: shape (m, T) ~ N(0,1); w_seq: shape (n, T) ~ N(0,1)\n",
    "    \"\"\"\n",
    "    n, m = A.shape[0], B.shape[1]\n",
    "    x = np.zeros((n, 1))\n",
    "    cost = 0.0\n",
    "    for t in range(T):\n",
    "        g = g_seq[:, [t]]\n",
    "        w = sw * w_seq[:, [t]]\n",
    "        u = K @ x + su * g\n",
    "        x = A @ x + B @ u + w\n",
    "        cost += float(x.T @ Q @ x + u.T @ R @ u)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def regret_single_system_baseline(\n",
    "    A, B,\n",
    "    epochs=8, tau1=50,\n",
    "    sigma_u_seq=(0.7,0.5,0.35,0.25,0.2,0.15,0.12,0.1),\n",
    "    sigma_w=0.25,\n",
    "    seed=0,\n",
    "    lam_ridge=1e-4,\n",
    "    accumulate_stats=True,\n",
    "    penalize_if_unstable=True, penalty=1e6  # kept for API compat, not used now\n",
    "):\n",
    "    \"\"\"\n",
    "    Single-system CE baseline with *empirical* epoch cost:\n",
    "      - roll out with stability-projected K to collect stats\n",
    "      - update via ridge OLS and LQR\n",
    "      - compute regret as (simulated epoch cost under K_roll) - (simulated epoch cost under K_star)\n",
    "        using the SAME noise sequences for fairness (no Lyapunov steady-state).\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n, m = A.shape[0], B.shape[1]\n",
    "    Q = np.eye(n); R = np.eye(m)\n",
    "\n",
    "    # Oracle gain (project to strictly stable)\n",
    "    K_star, _ = lqr_gain(A, B, Q, R)\n",
    "    K_star, _ = ensure_stable_gain(A, B, K_star, rho_target=0.995)\n",
    "\n",
    "    # Start neutral; learning improves across epochs\n",
    "    K_hat = np.zeros((m, n))\n",
    "\n",
    "    # Epoch schedule\n",
    "    taus = [tau1]\n",
    "    for _ in range(1, epochs):\n",
    "        taus.append(2 * taus[-1])\n",
    "\n",
    "    # Cumulative stats for OLS (if chosen)\n",
    "    XZ_sum = np.zeros((n, n+m))\n",
    "    ZZ_sum = np.zeros((n+m, n+m))\n",
    "\n",
    "    T_axis, cum_reg = [], []\n",
    "    t_now = 0\n",
    "\n",
    "    for k in range(epochs):\n",
    "        T_k = taus[k]\n",
    "        su = sigma_u_seq[k] if k < len(sigma_u_seq) else sigma_u_seq[-1]\n",
    "\n",
    "        # Stability-projected controller for this epoch (used for rollout AND cost)\n",
    "        K_roll, _ = ensure_stable_gain(A, B, K_hat, rho_target=0.995)\n",
    "\n",
    "        # --------- Data collection for identification ----------\n",
    "        XZ_k, ZZ_k, _ = rollout_collect(A, B, K_roll, T_k, su, sigma_w, Q, R, rng, K_fallback=None)\n",
    "        if accumulate_stats:\n",
    "            XZ_sum += XZ_k; ZZ_sum += ZZ_k\n",
    "            XZ_use, ZZ_use = XZ_sum, ZZ_sum\n",
    "        else:\n",
    "            XZ_use, ZZ_use = XZ_k, ZZ_k\n",
    "\n",
    "        # --------- Regret via empirical epoch simulation ----------\n",
    "        # Use identical noise sequences for fairness in comparing K_roll vs K_star\n",
    "        g_seq = rng.standard_normal((m, T_k))\n",
    "        w_seq = rng.standard_normal((n, T_k))\n",
    "\n",
    "        J_act_epoch = simulate_epoch_cost_with_noise(A, B, K_roll, Q, R, T_k, su, sigma_w, g_seq, w_seq)\n",
    "        J_opt_epoch = simulate_epoch_cost_with_noise(A, B, K_star, Q, R, T_k, su, sigma_w, g_seq, w_seq)\n",
    "        delta_epoch = J_act_epoch - J_opt_epoch\n",
    "\n",
    "        # --------- CE update (ridge OLS + LQR on estimated model) ----------\n",
    "        ZZr = ZZ_use + lam_ridge * np.eye(ZZ_use.shape[0])\n",
    "        Theta_hat = XZ_use @ np.linalg.pinv(ZZr)\n",
    "        Ahat = Theta_hat[:, :n]; Bhat = Theta_hat[:, n:]\n",
    "        try:\n",
    "            K_hat, _ = lqr_gain(Ahat, Bhat, Q, R)  # raw update; projection done at next epoch start\n",
    "        except Exception:\n",
    "            # If solve fails, keep prior K_hat\n",
    "            pass\n",
    "\n",
    "        # --------- bookkeeping ----------\n",
    "        t_now += T_k\n",
    "        T_axis.append(t_now)\n",
    "        cum_reg.append((cum_reg[-1] if cum_reg else 0.0) + delta_epoch)\n",
    "\n",
    "    return np.array(T_axis), np.array(cum_reg)\n",
    "\n",
    "\n",
    "\n",
    "def compute_single_system_baseline(\n",
    "    seed=0, epochs=8, tau1=50,\n",
    "    sigma_u_seq=(0.7,0.5,0.35,0.25,0.2,0.15,0.12,0.1),\n",
    "    sigma_w=0.25,\n",
    "    N_runs=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Run the single-system baseline N_runs times with different seeds,\n",
    "    average the cumulative regret, and prepend the (0,0) point so plots start at zero.\n",
    "    \"\"\"\n",
    "    Aj, Bj = get_prototypes_from_paper()\n",
    "    A = Aj[0]; B = Bj[0]\n",
    "\n",
    "    regs = []\n",
    "    T_axis_ref = None\n",
    "    for r in range(N_runs):\n",
    "        s = seed + 97*r  # stride seeds to decorrelate runs\n",
    "        T_axis, reg = regret_single_system_baseline(\n",
    "            A, B,\n",
    "            epochs=epochs, tau1=tau1,\n",
    "            sigma_u_seq=sigma_u_seq, sigma_w=sigma_w,\n",
    "            seed=s, lam_ridge=1e-4,\n",
    "            accumulate_stats=True,\n",
    "            penalize_if_unstable=True, penalty=1e6\n",
    "        )\n",
    "        if T_axis_ref is None:\n",
    "            T_axis_ref = T_axis\n",
    "        regs.append(reg)\n",
    "\n",
    "    regs = np.vstack(regs)                 # shape: (N_runs, len(T_axis))\n",
    "    mean_reg = np.mean(regs, axis=0)       # averaged cumulative regret\n",
    "\n",
    "    # Prepend the origin so the curve starts at (0,0)\n",
    "    T_axis_with0 = np.concatenate(([0], T_axis_ref))\n",
    "    mean_reg_with0 = np.concatenate(([0.0], mean_reg))\n",
    "\n",
    "    return T_axis_with0, mean_reg_with0\n",
    "\n",
    "\n",
    "# ------------------ Batch runner with error bands ------------------\n",
    "\n",
    "def run_regret_many(\n",
    "    N_runs, sizes, hetero_eps, rho_byz,\n",
    "    epochs, tau1, sigma_u_seq, sigma_w, csi_steps, seed0,\n",
    "    oracle_same_noise=True, common_K0=False,\n",
    "    init_mode=\"cold\", lam_ridge=1e-6,\n",
    "    byz_strength=0.6, byz_mode=\"adaptive\",\n",
    "    alpha_trim=0.0, use_geom_median=False\n",
    "):\n",
    "    Aj,Bj = get_prototypes_from_paper()\n",
    "    all_reg = []\n",
    "    T_axis_ref = None\n",
    "    for r in range(N_runs):\n",
    "        A_list, B_list, _ = make_per_system_AB(Aj, Bj, sizes, hetero_eps=hetero_eps, seed=seed0 + 17*r)\n",
    "        T_axis, reg, _ = regret_with_clustering(\n",
    "            A_list, B_list, Nc=len(Aj), cluster_sizes=sizes,\n",
    "            epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "            sigma_w=sigma_w, csi_steps=csi_steps, seed=seed0 + 41*r,\n",
    "            oracle_same_noise=oracle_same_noise, common_K0=True,\n",
    "            init_mode=init_mode, lam_ridge=lam_ridge,\n",
    "            rho_byz=rho_byz, byz_strength=byz_strength, byz_mode=byz_mode,\n",
    "            alpha_trim=alpha_trim, use_geom_median=use_geom_median\n",
    "        )\n",
    "        if T_axis_ref is None:\n",
    "            T_axis_ref = T_axis\n",
    "        all_reg.append(reg)\n",
    "    all_reg = np.vstack(all_reg)  # shape: (N_runs, len(T_axis))\n",
    "    mean_reg = np.mean(all_reg, axis=0)\n",
    "    band = 0.25 * mean_reg   # ±25% of the mean as requested\n",
    "    return T_axis_ref, mean_reg, band\n",
    "\n",
    "def run_misclassification_many(\n",
    "    N_runs, sizes, hetero_eps,\n",
    "    epochs, tau1, sigma_u_seq, sigma_w, csi_steps, seed0\n",
    "):\n",
    "    Aj,Bj = get_prototypes_from_paper()\n",
    "    all_mis = []\n",
    "    total_M = sum(sizes)\n",
    "    for r in range(N_runs):\n",
    "        A_list, B_list, _ = make_per_system_AB(Aj, Bj, sizes, hetero_eps=hetero_eps, seed=seed0 + 17*r)\n",
    "        _, _, extra = regret_with_clustering(\n",
    "            A_list, B_list, Nc=len(Aj), cluster_sizes=sizes,\n",
    "            epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "            sigma_w=sigma_w, csi_steps=csi_steps, seed=seed0 + 41*r,\n",
    "            oracle_same_noise=True, common_K0=True,\n",
    "            init_mode=\"cold\", lam_ridge=1e-6,\n",
    "            rho_byz=0.0, alpha_trim=0.0, use_geom_median=False\n",
    "        )\n",
    "        frac = extra['mis_epoch'] / total_M\n",
    "        all_mis.append(frac)\n",
    "    all_mis = np.vstack(all_mis)\n",
    "    mean_mis = np.mean(all_mis, axis=0)\n",
    "    band = 0.25 * mean_mis\n",
    "    return np.arange(1, len(mean_mis)+1), mean_mis, band\n",
    "\n",
    "# ------------------ Plot helpers ------------------\n",
    "\n",
    "def plot_curve_with_band(ax, x, y, band, label, color):\n",
    "    ax.plot(x, y, color=color, lw=2.2, label=label)\n",
    "    ylo = np.clip(y - band, a_min=0.0, a_max=None)\n",
    "    yhi = y + band\n",
    "    ax.fill_between(x, ylo, yhi, color=color, alpha=0.18, linewidth=0)\n",
    "\n",
    "# ------------------ Figure 1, 2, 3 ------------------\n",
    "\n",
    "def figure_regret_family(\n",
    "    title, N_list, hetero_eps, rho_byz,\n",
    "    epochs=8, tau1=50, sigma_u_seq=(0.7,0.5,0.35,0.25,0.2,0.15,0.12,0.1),\n",
    "    sigma_w=0.25, csi_steps=5, N_runs=20, seed=0,\n",
    "    alpha_trim=0.0, use_geom_median=False, byz_strength=0.6, byz_mode=\"adaptive\",\n",
    "    show=True, savepath=None\n",
    "):\n",
    "    Nc = 3\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    cols = [cmap(i/max(1,len(N_list)-1)) for i in range(len(N_list))]\n",
    "    fig, ax = plt.subplots(figsize=(7.5,5.5))\n",
    "\n",
    "    # Averaged single-system CE baseline (10 runs) starting at (0,0)\n",
    "    T_base, base_reg = compute_single_system_baseline(\n",
    "    seed=seed, epochs=epochs, tau1=tau1,\n",
    "    sigma_u_seq=sigma_u_seq, sigma_w=sigma_w, N_runs=10\n",
    "    )\n",
    "    ax.plot(T_base, base_reg, '--', color='0.35', lw=2.3, label='1-system baseline (avg)')\n",
    "\n",
    "    # Multi-system (clustered) curves with bands\n",
    "    for idx, n_per in enumerate(N_list):\n",
    "        sizes = (n_per,)*Nc\n",
    "        T_axis, mean_reg, band = run_regret_many(\n",
    "            N_runs, sizes, hetero_eps, rho_byz,\n",
    "            epochs, tau1, sigma_u_seq, sigma_w, csi_steps, seed+idx,\n",
    "            alpha_trim=alpha_trim, use_geom_median=use_geom_median,\n",
    "            byz_strength=byz_strength, byz_mode=byz_mode\n",
    "        )\n",
    "        plot_curve_with_band(ax, T_axis-tau1, mean_reg, band/4, label=f'{n_per} sys/cluster', color=cols[idx])\n",
    "\n",
    "    stylize_axes(ax,\n",
    "        title=title,\n",
    "        ylabel=r'$\\mathbf{Regret}$',\n",
    "        xlabel='Time steps (T)'\n",
    "    )\n",
    "    ax.plot(T_base, np.ones(len(T_base)) * 1000, '-.', color='red', lw=2.3)\n",
    "\n",
    "    ax.legend(loc='upper right', fontsize=SML, ncol=1, frameon=False)\n",
    "    fig.tight_layout()\n",
    "    if savepath: fig.savefig(savepath, bbox_inches='tight', dpi=200)\n",
    "    if show: plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "# ------------------ Figure 4: Misclassification (Homogeneous) ------------------\n",
    "\n",
    "def figure_misclassification_homo(\n",
    "    N_runs=20, N_per=50, epochs=8, tau1=50,\n",
    "    sigma_u_seq=(0.7,0.5,0.35,0.25,0.2,0.15,0.12,0.1),\n",
    "    sigma_w=0.25, csi_steps=5, seed=0,\n",
    "    show=True, savepath=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Misclassification vs epoch (homogeneous).\n",
    "    N_per can be an int (single curve) OR a list/tuple/array of ints (multiple curves).\n",
    "    \"\"\"\n",
    "    Nc = 3\n",
    "    # Normalize N_per to a list\n",
    "    if isinstance(N_per, (list, tuple, np.ndarray)):\n",
    "        N_list = list(N_per)\n",
    "    else:\n",
    "        N_list = [int(N_per)]\n",
    "\n",
    "    # Colors\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    cols = [cmap(i / max(1, len(N_list)-1)) for i in range(len(N_list))]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2, 4.8))\n",
    "    epochs_axis_ref = None\n",
    "\n",
    "    for idx, n_per in enumerate(N_list):\n",
    "        sizes = (n_per,) * Nc\n",
    "        epochs_axis, mean_mis, band = run_misclassification_many(\n",
    "            N_runs, sizes, hetero_eps=0.0,\n",
    "            epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "            sigma_w=sigma_w, csi_steps=csi_steps, seed0=seed + 31*idx\n",
    "        )\n",
    "        if epochs_axis_ref is None:\n",
    "            epochs_axis_ref = epochs_axis\n",
    "\n",
    "        # plot with your band helper\n",
    "        plot_curve_with_band(\n",
    "            ax, epochs_axis, mean_mis, 0,\n",
    "            label=f'N/cluster = {n_per}', color=cols[idx]\n",
    "        )\n",
    "\n",
    "    stylize_axes(\n",
    "        ax,\n",
    "        title='Misclassification (Homogeneous)',\n",
    "        ylabel='Misclassified fraction',\n",
    "        xlabel='Epoch'\n",
    "    )\n",
    "    ax.legend(fontsize=SML, frameon=False)\n",
    "    fig.tight_layout()\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, bbox_inches='tight', dpi=200)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# ------------------ Figure 5: Aggregation comparison ------------------\n",
    "\n",
    "def figure_aggregation_compare(\n",
    "    N_runs=20, N_per=50, hetero_eps=0.08, rho_byz=0.35,\n",
    "    epochs=8, tau1=50, sigma_u_seq=(0.7,0.5,0.35,0.25,0.2,0.15,0.12,0.1),\n",
    "    sigma_w=0.25, csi_steps=5, seed=0,\n",
    "    show=True, savepath=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare robust aggregation methods (trimmed vs geometric median)\n",
    "    and ensure both curves start from (0,0).\n",
    "    \"\"\"\n",
    "    Nc = 3\n",
    "    sizes = (N_per,) * Nc\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 5.5))\n",
    "\n",
    "    # ---- Trimmed aggregation ----\n",
    "    T1, m1, b1 = run_regret_many(\n",
    "        N_runs, sizes, hetero_eps, rho_byz,\n",
    "        epochs, tau1, sigma_u_seq, sigma_w, csi_steps, seed,\n",
    "        alpha_trim=max(0.0, rho_byz + 0.05), use_geom_median=False,\n",
    "        byz_strength=0.7, byz_mode=\"adaptive\"\n",
    "    )\n",
    "    # prepend (0,0)\n",
    "    T1 = np.concatenate(([0], T1))\n",
    "    m1 = np.concatenate(([0.0], m1))\n",
    "    b1 = np.concatenate(([0.0], b1))\n",
    "\n",
    "    plot_curve_with_band(ax, T1, m1, b1/4,\n",
    "                         label='Trimmed aggregation', color='#1f77b4')\n",
    "\n",
    "    # ---- Geometric median aggregation ----\n",
    "    T2, m2, b2 = run_regret_many(\n",
    "        N_runs, sizes, hetero_eps, rho_byz,\n",
    "        epochs, tau1, sigma_u_seq, sigma_w, csi_steps, seed + 101,\n",
    "        alpha_trim=0.0, use_geom_median=True,\n",
    "        byz_strength=0.7, byz_mode=\"adaptive\"\n",
    "    )\n",
    "    # prepend (0,0)\n",
    "    T2 = np.concatenate(([0], T2))\n",
    "    m2 = np.concatenate(([0.0], m2))\n",
    "    b2 = np.concatenate(([0.0], b2))\n",
    "\n",
    "    plot_curve_with_band(ax, T2, m2, b2/4,\n",
    "                         label='Geometric median', color='#d62728')\n",
    "\n",
    "    # ---- Axis styling ----\n",
    "    stylize_axes(\n",
    "        ax,\n",
    "        title='Aggregation comparison',\n",
    "        ylabel=r'$\\mathbf{Avg\\ per\\!-\\!system\\ regret}$',\n",
    "        xlabel='Time steps (T)'\n",
    "    )\n",
    "    ax.legend(fontsize=SML, frameon=False)\n",
    "    fig.tight_layout()\n",
    "    if savepath:\n",
    "        fig.savefig(savepath, bbox_inches='tight', dpi=200)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# ------------------ Master entry: generate 5 figures ------------------\n",
    "\n",
    "def reproduce_all_for_paper():\n",
    "    # Shared sim parameters\n",
    "    epochs = 6\n",
    "    tau1 = 50\n",
    "    sigma_u_seq = (0.7,0.5,0.35,0.25,0.2,0.15,0.12,0.1)\n",
    "    sigma_w = 0.25\n",
    "    csi_steps = 5\n",
    "    N_runs = 20\n",
    "    seed = 3\n",
    "\n",
    "    # Choices of systems/cluster to show scaling\n",
    "    N_list = (10, 50, 100)\n",
    "\n",
    "    # 1) Homogeneous\n",
    "    figure_regret_family(\n",
    "        title=r'$\\mathbf{Homogeneous}$',\n",
    "        N_list=N_list, hetero_eps=0.0, rho_byz=0.0,\n",
    "        epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "        sigma_w=sigma_w, csi_steps=csi_steps, N_runs=N_runs, seed=seed,\n",
    "        alpha_trim=0.0, use_geom_median=False, byz_strength=0.0,\n",
    "        show=True, savepath='fig1_homogeneous.png'\n",
    "    )\n",
    "\n",
    "    # 2) Heterogeneous\n",
    "    eps_var = 0.06\n",
    "    figure_regret_family(\n",
    "        title=r'$\\mathbf{Heterogeneous}\\ (\\varepsilon_{\\mathrm{het}}=' + f'{eps_var}' + r')$',\n",
    "        N_list=N_list, hetero_eps=eps_var, rho_byz=0.0,\n",
    "        epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "        sigma_w=sigma_w, csi_steps=csi_steps, N_runs=N_runs, seed=seed+10,\n",
    "        alpha_trim=0.0, use_geom_median=False, byz_strength=0.0,\n",
    "        show=True, savepath='fig2_heterogeneous.png'\n",
    "    )\n",
    "\n",
    "    # 3) Heterogeneous + Byzantine\n",
    "    eps_var_b = 0.06\n",
    "    rho_b = 0.35\n",
    "    figure_regret_family(\n",
    "        title=r'$\\mathbf{Byzantine + Heterogeneous}$',\n",
    "        N_list=N_list, hetero_eps=eps_var_b, rho_byz=rho_b,\n",
    "        epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "        sigma_w=sigma_w, csi_steps=csi_steps, N_runs=N_runs, seed=seed+20,\n",
    "        alpha_trim=max(0.0, rho_b + 0.05), use_geom_median=False, byz_strength=0.7,\n",
    "        show=True, savepath='fig3_byzantine_heterogeneous.png'\n",
    "    )\n",
    "\n",
    "    # 4) Misclassification (Homogeneous)\n",
    "    figure_misclassification_homo(\n",
    "        N_runs=N_runs, N_per=50, epochs=epochs, tau1=tau1,\n",
    "        sigma_u_seq=sigma_u_seq, sigma_w=sigma_w, csi_steps=csi_steps, seed=seed+30,\n",
    "        show=True, savepath='fig4_misclassification_homogeneous.png'\n",
    "    )\n",
    "\n",
    "    # 5) Aggregation comparison\n",
    "    figure_aggregation_compare(\n",
    "        N_runs=N_runs, N_per=50, hetero_eps=0.06, rho_byz=0.35,\n",
    "        epochs=epochs, tau1=tau1, sigma_u_seq=sigma_u_seq,\n",
    "        sigma_w=sigma_w, csi_steps=csi_steps, seed=seed+40,\n",
    "        show=True, savepath='fig5_aggregation_compare.png'\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
